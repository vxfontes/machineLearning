{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install haystack-ai pandas datasets matplotlib python-dotenv qdrant-client langchain-openai langchain_community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/vx/Desktop/coding/machineLearning/.venv/lib/python3.13/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rajpurkar/squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_union = pd.concat([pd.DataFrame(dataset['train']), pd.DataFrame(dataset['validation'])], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separação de informações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o dataset tem esse formato\n",
    "- Index(['id', 'title', 'context', 'question', 'answers'], dtype='object')\n",
    "\n",
    "#### Contexto\n",
    "existem dois tipos de separação para contexto\n",
    "- mantendo todas as tuplas separadamente, ou seja, title e seu context correspondente\n",
    "- unindo todos os context de um mesmo title, reduzindo bastante o numero de tuplas e deixando os contextos mais completos\n",
    "\n",
    "#### Perguntas e Resposta (Q&A)\n",
    "- obtendo o titulo, pergunta e resposta de cada tupla e salvando individualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Contexto(Enum):\n",
    "    GERAIS_100 = 'contexto_gerais_100'\n",
    "    GERAIS_50 = 'contexto_gerais_50'\n",
    "    GERAIS_25 = 'contexto_gerais_25'\n",
    "    GERAIS_15 = 'contexto_gerais_15'\n",
    "    PORTITULO_100 = 'contexto_portitulo_100'\n",
    "    PORTITULO_50 = 'contexto_portitulo_50'\n",
    "    PORTITULO_25 = 'contexto_portitulo_25'\n",
    "    PORTITULO_15 = 'contexto_portitulo_15'\n",
    "    QA_PAIRS = 'qa_pairs'\n",
    "    QA_PAIRS_PORTITULO_100 = 'qa_pairs_portitulo_100'\n",
    "    QA_PAIRS_PORTITULO_50 = 'qa_pairs_portitulo_50'\n",
    "    QA_PAIRS_PORTITULO_25 = 'qa_pairs_portitulo_25'\n",
    "    QA_PAIRS_PORTITULO_15 = 'qa_pairs_portitulo_15'\n",
    "    QA_PAIRS_GERAIS_100 = 'qa_pairs_gerais_100'\n",
    "    QA_PAIRS_GERAIS_50 = 'qa_pairs_gerais_50'\n",
    "    QA_PAIRS_GERAIS_25 = 'qa_pairs_gerais_25'\n",
    "    QA_PAIRS_GERAIS_15 = 'qa_pairs_gerais_15'\n",
    "    TESTE_PORTITULO = 'contexto_portitulo_teste'\n",
    "    TESTE_GERAIS = 'contexto_gerais_teste'\n",
    "    QA_TESTE_PORTITULO = 'qa_teste_portitulo'\n",
    "    QA_TESTE_GERAIS = 'qa_teste_gerais'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unindo contextos por titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_contexts(group):\n",
    "    # Remover duplicatas dentro de um mesmo título\n",
    "    unique_contexts = set(group)\n",
    "    # Juntar os contextos em um único texto corrido\n",
    "    return \" \".join(unique_contexts)\n",
    "\n",
    "contextos_df_unindo = data_union.copy().groupby(\"title\")[\"context\"].apply(consolidate_contexts).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos gerados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 100% dos dados (embaralhados)\n",
    "contextos_df_unindo.to_csv(f'''data/{Contexto.PORTITULO_100.value}.csv''', index=False)\n",
    "\n",
    "# 50% dos dados\n",
    "contextos_df_unindo.sample(frac=0.5, random_state=42).to_csv(f'''data/{Contexto.PORTITULO_50.value}.csv''', index=False)\n",
    "\n",
    "# 25% dos dados\n",
    "contextos_df_unindo.sample(frac=0.25, random_state=42).to_csv(f'''data/{Contexto.PORTITULO_25.value}.csv''', index=False)\n",
    "\n",
    "# 15% dos dados\n",
    "contextos_df_unindo.sample(frac=0.15, random_state=42).to_csv(f'''data/{Contexto.PORTITULO_15.value}.csv''', index=False)\n",
    "\n",
    "print(\"Arquivos gerados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sem unir por titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextos_df_title = data_union.copy()\n",
    "contextos_df_title = contextos_df_title[[\"title\", \"context\"]]\n",
    "\n",
    "# Embaralha os dados antes de amostrar\n",
    "contextos_df_title = contextos_df_title.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos gerados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 100% dos dados\n",
    "contextos_df_title.to_csv(f'''data/{Contexto.GERAIS_100.value}.csv''', index=False)\n",
    "\n",
    "# 50% dos dados\n",
    "contextos_df_title.sample(frac=0.5, random_state=42).to_csv(f'''data/{Contexto.GERAIS_50.value}.csv''', index=False)\n",
    "\n",
    "# 25% dos dados\n",
    "contextos_df_title.sample(frac=0.25, random_state=42).to_csv(f'''data/{Contexto.GERAIS_25.value}.csv''', index=False)\n",
    "\n",
    "# 15% dos dados\n",
    "contextos_df_title.sample(frac=0.15, random_state=42).to_csv(f'''data/{Contexto.GERAIS_15.value}.csv''', index=False)\n",
    "\n",
    "print(\"Arquivos gerados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separando qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/gxpxpsfx2y5g_0qfn36b5jcw0000gn/T/ipykernel_77397/590395369.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qa_df['answers'] = qa_df.apply(extract_answers, axis=1)\n"
     ]
    }
   ],
   "source": [
    "qa_df = data_union[[\"title\", \"question\", \"answers\"]]\n",
    "\n",
    "def extract_answers(row):\n",
    "    return row['answers']['text']\n",
    "\n",
    "qa_df['answers'] = qa_df.apply(extract_answers, axis=1)\n",
    "qa_df = qa_df[qa_df['answers'].str.len() > 0]\n",
    "\n",
    "def process_answers(answer_list):\n",
    "    if not isinstance(answer_list, list):\n",
    "        return answer_list  # Retorna diretamente caso não seja uma lista\n",
    "    \n",
    "    unique_answers = list(set(answer_list))  # Remove duplicatas\n",
    "    \n",
    "    if len(unique_answers) == 1:\n",
    "        return unique_answers[0]  # Retorna como string se houver apenas um item único\n",
    "    \n",
    "    return unique_answers  # Retorna a lista se houver múltiplos valores distintos\n",
    "\n",
    "qa_df['answers'] = qa_df['answers'].apply(process_answers)\n",
    "\n",
    "qa_df.to_csv(f'''data/qa/{Contexto.QA_PAIRS.value}_geral.csv''', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## haystack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inicializando itens do haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers import InMemoryEmbeddingRetriever\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
    "from haystack.components.embedders import OpenAIDocumentEmbedder, OpenAITextEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- montando pipeline de indexacao de documentos\n",
    "- montando pipeline de recuperação e geração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(source_file: str, qa_passado_df: pd.DataFrame, output_filename: str):\n",
    "    text_file_converter = TextFileToDocument()\n",
    "    cleaner = DocumentCleaner()\n",
    "    splitter = DocumentSplitter()\n",
    "    embedder = OpenAIDocumentEmbedder()\n",
    "    indexing_pipeline = Pipeline()\n",
    "\n",
    "    text_embedder = OpenAITextEmbedder()\n",
    "    template = \"\"\"Given these contexts, answer the question.\n",
    "                    Context:\n",
    "                    {% for doc in documents %}\n",
    "                        {{ doc.content }}\n",
    "                    {% endfor %}\n",
    "                    Question: {{query}}\n",
    "                    Answer:\"\"\"\n",
    "    prompt_builder = PromptBuilder(template=template)\n",
    "    llm = OpenAIGenerator()\n",
    "    rag_pipeline = Pipeline()\n",
    "\n",
    "    print('------------------- montando pipeline de indexação de docs')\n",
    "    document_store = InMemoryDocumentStore()\n",
    "    writer = DocumentWriter(document_store)\n",
    "    retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "    \n",
    "    indexing_pipeline.add_component(\"converter\", text_file_converter)\n",
    "    indexing_pipeline.add_component(\"cleaner\", cleaner)\n",
    "    indexing_pipeline.add_component(\"splitter\", splitter)\n",
    "    indexing_pipeline.add_component(\"embedder\", embedder)\n",
    "    indexing_pipeline.add_component(\"writer\", writer)\n",
    "\n",
    "    indexing_pipeline.connect(\"converter.documents\", \"cleaner.documents\")\n",
    "    indexing_pipeline.connect(\"cleaner.documents\", \"splitter.documents\")\n",
    "    indexing_pipeline.connect(\"splitter.documents\", \"embedder.documents\")\n",
    "    indexing_pipeline.connect(\"embedder.documents\", \"writer.documents\")\n",
    "\n",
    "    print('------------------- pipeline montada, lendo arquivo')\n",
    "    indexing_pipeline.run(data={\"sources\": [f'''data/{source_file}.csv''']})\n",
    "\n",
    "    print(f\"Documentos do arquivo {source_file} indexados com sucesso!\")\n",
    "    print('------------------- montando pipelines de rag (retriver e generator)')\n",
    "\n",
    "    rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "    rag_pipeline.add_component(\"retriever\", retriever)\n",
    "    rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "    rag_pipeline.add_component(\"llm\", llm)\n",
    "\n",
    "    rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "    rag_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "    rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "\n",
    "    print('------------------- pipelines de rag montada')\n",
    "\n",
    "    print('------------------- iniciando testes de perguntas e respostas')\n",
    "\n",
    "    results = []\n",
    "    i = 0\n",
    "    total = len(qa_passado_df)\n",
    "    \n",
    "    for index, row in qa_passado_df.iterrows():\n",
    "        query = row[\"question\"]\n",
    "        expected_answer = row[\"answers\"]\n",
    "        \n",
    "        generated_answer = rag_pipeline.run(data={\"prompt_builder\": {\"query\": query}, \"text_embedder\": {\"text\": query}})\n",
    "\n",
    "        results.append({\n",
    "            \"title\": row[\"title\"],\n",
    "            \"question\": query,\n",
    "            \"expected_answer\": expected_answer,\n",
    "            \"generated_answer\": generated_answer[\"llm\"][\"replies\"],\n",
    "        })\n",
    "        i += 1\n",
    "\n",
    "        print(f\"################### Processando ({i}/{total})...\")\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f'''data/qa/{output_filename}.csv''', index=False)\n",
    "\n",
    "    print(f\"\\n-------------------Finalizado! Resultados salvos em {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resultados haystack por titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df_5_porcento = qa_df.sample(frac=0.05, random_state=42)\n",
    "qa_df_01_porcento = qa_df.sample(frac=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_df_usado = qa_df.copy()\n",
    "# qa_df_usado.to_csv(f'''data/qa/{Contexto.QA_PAIRS.value}_usado.csv''')\n",
    "qa_df_usado = pd.read_csv(f'''data/qa/{Contexto.QA_PAIRS.value}_usado.csv''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df_usado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(Contexto.PORTITULO_15.value, qa_df_usado, Contexto.QA_PAIRS_PORTITULO_15.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(Contexto.PORTITULO_25.value, qa_df_usado, Contexto.QA_PAIRS_PORTITULO_25.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(Contexto.PORTITULO_50.value, qa_df_usado, Contexto.QA_PAIRS_PORTITULO_50.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(Contexto.PORTITULO_100.value, qa_df_usado, Contexto.QA_PAIRS_PORTITULO_100.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resultados haystack geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(Contexto.GERAIS_15.value, qa_df_usado, Contexto.QA_PAIRS_GERAIS_15.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(Contexto.GERAIS_25.value, qa_df_usado, Contexto.QA_PAIRS_GERAIS_25.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(Contexto.GERAIS_50.value, qa_df_usado, Contexto.QA_PAIRS_GERAIS_50.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(Contexto.GERAIS_100.value, qa_df_usado, Contexto.QA_PAIRS_GERAIS_100.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparação de respostas com llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "def use_llm(esperada, obtida):\n",
    "    cliente = OpenAI(api_key=api_key)\n",
    "\n",
    "    prompt = f'''\n",
    "        Você é um assistente que compara textos. \n",
    "        Compare a resposta esperada '{esperada}' com a resposta adquirida '{obtida}' e diga se são semanticamente semelhantes. \n",
    "\n",
    "        Responda em uma escala de 0 a 10, onde 0 significa que os textos são completamente diferentes e 10 significa que são idênticos em sentido e semanticamente.\n",
    "\n",
    "        Tente entender o sentido completo da resposta, não apenas palavras-chave.\n",
    "        Mas também se atente a detalhes como palavras-chave e seus significados.\n",
    "        Por exemplo, orações com palavras diferentes mas com o mesmo significado devem ser consideradas semelhantes.\n",
    "        Em caso de datas, números ou informações específicas, considere a semelhança do contexto em que estão inseridos.\n",
    "\n",
    "        Importante: Uma resposta adquirida pode ser mais longa e detalhada que a resposta esperada. Isso não necessariamente a torna diferente, desde que ela ainda aborde o mesmo tópico e não contradiga a resposta esperada. Portanto, mesmo que a resposta adquirida seja mais longa, se ela ainda estiver alinhada com a resposta esperada, considere-a semelhante.\n",
    "\n",
    "        Responda apenas o número equivalente à semelhança dos textos.\n",
    "\n",
    "        # exemplo de saida\n",
    "        10\n",
    "    '''\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = cliente.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        store=True,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def remove_specific_characters(input_string):\n",
    "    input_string = re.sub(r'(?<=[a-zA-Z])\\.', '', input_string)\n",
    "    input_string = re.sub(r'[\\[\\]\\'\\\"]', '', input_string)\n",
    "    return input_string\n",
    "\n",
    "def is_similar_using_llm(esperada: str = \"\",obtida: str = \"\"):\n",
    "    if isinstance(esperada, list):\n",
    "        esperada = esperada[0]\n",
    "    if isinstance(obtida, list):\n",
    "        obtida = obtida[0]\n",
    "\n",
    "    esperada = remove_specific_characters(esperada)\n",
    "    obtida = remove_specific_characters(obtida)\n",
    "    response = use_llm(esperada, obtida)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste 1: 5, Teste 2: 0, Teste 3: 10, Teste 4 que devia dar 10: 8, Teste 5 que devia dar 10: 7\n"
     ]
    }
   ],
   "source": [
    "teste = is_similar_using_llm(\"archdioceses or departments of the Roman Curia\", \"The Roman Curia.\")\n",
    "teste2 = is_similar_using_llm('Central Standard Time',\"['The contexts provided do not mention Saskatoon or its time observance specific to time zones, Daylight Saving Time, or any other relevant information. Therefore, based on the information given, I cannot determine what time Saskatoon observes all year long.']\")\n",
    "teste3 = is_similar_using_llm('VHF omnidirectional range',['VOR stands for VHF Omnidirectional Range.'])\n",
    "teste4 = is_similar_using_llm('32nd',\"['In 2009, Tucson ranked as the 32nd largest city in the United States.']\")\n",
    "teste5 = is_similar_using_llm('1996',\"['Labour published a new draft manifesto in 1996, called \"\"New Labour, New Life For Britain.\"\"']\")\n",
    "print(f\"Teste 1: {teste}, Teste 2: {teste2}, Teste 3: {teste3}, Teste 4 que devia dar 10: {teste4}, Teste 5 que devia dar 10: {teste5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "frase1=\"email, web-hosting, or online storage services\"\n",
    "frase2=\"['Internet hosting services provide the infrastructure and technology needed to make websites accessible on the Internet. This includes server space for storing website files, bandwidth for transmitting data to users, domain name registration, email accounts, and often additional services such as database management, security features, and technical support. Hosting services enable individuals and organizations to have an online presence by hosting their web content and applications.']\"\n",
    "print(is_similar_using_llm(frase1, frase2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_respostas_usando_llm(arquivo_csv: str, qa='qa'):\n",
    "    df = pd.read_csv(f'''data/{qa}/{arquivo_csv}.csv''')\n",
    "    df['is_similar'] = df.apply(lambda row: is_similar_using_llm(row['expected_answer'], row['generated_answer']), axis=1)\n",
    "    df.to_csv(f'''data/{qa}/{arquivo_csv}.csv''', index=False)\n",
    "\n",
    "def compare_respostas_usando_llm_contagem(arquivo_csv: str, qa='qa'):\n",
    "    df = pd.read_csv(f'''data/{qa}/{arquivo_csv}.csv''')\n",
    "\n",
    "    count = 0\n",
    "    total = len(df)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        df.loc[index, 'is_similar'] = is_similar_using_llm(row['expected_answer'], row['generated_answer'])\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        print(f'*********** Progresso: {count}/{total}')\n",
    "\n",
    "    df.to_csv(f'''data/{qa}/{arquivo_csv}.csv''', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_GERAIS_15.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_GERAIS_25.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_GERAIS_50.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_GERAIS_100.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_PORTITULO_15.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_PORTITULO_25.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_PORTITULO_50.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_PORTITULO_100.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adicionando testes a parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextos_df_title.sample(frac=0.05, random_state=42).to_csv(f'''data/{Contexto.TESTE_PORTITULO.value}.csv''', index=False)\n",
    "contextos_df_unindo.sample(frac=0.05, random_state=42).to_csv(f'''data/{Contexto.TESTE_GERAIS.value}.csv''', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df_novo = qa_df.sample(frac=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(Contexto.TESTE_PORTITULO.value, qa_df_novo, Contexto.QA_TESTE_PORTITULO.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(Contexto.TESTE_GERAIS.value, qa_df_novo, Contexto.QA_TESTE_PORTITULO.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_TESTE_PORTITULO.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_TESTE_GERAIS.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avaliando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base que quero avaliar\n",
    "QA_avaliado = Contexto.QA_PAIRS_GERAIS_100.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obtendo_respostas = pd.read_csv(f'''data/qa/{QA_avaliado}.csv''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um dicionário para armazenar a contagem por faixa de 0 a 10\n",
    "bins = list(range(11))  # Criando bins de 0 a 10\n",
    "\n",
    "# Contar as ocorrências em cada faixa\n",
    "contagem = obtendo_respostas[\"is_similar\"].value_counts().sort_index()\n",
    "contagem = contagem.reindex(bins, fill_value=0)  # Garantir que todas as faixas apareçam\n",
    "\n",
    "# Calcular porcentagem\n",
    "total = contagem.sum()\n",
    "porcentagem = (contagem / total) * 100\n",
    "\n",
    "\n",
    "# Exibir a tabela de porcentagens\n",
    "print(f'Distribuição de similaridade no dataset {QA_avaliado} (%):')\n",
    "print(porcentagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cores = [\"blue\", \"red\", \"green\", \"purple\", \"orange\", \"brown\", \"pink\", \"gray\", \"cyan\", \"magenta\"]\n",
    "\n",
    "# Criando um gráfico de barras\n",
    "plt.figure(figsize=(6, 4))\n",
    "obtendo_respostas[\"is_similar\"].value_counts().plot(kind=\"bar\", color=cores)\n",
    "plt.title(f'''Distribuição de similaridade {QA_avaliado}''')\n",
    "plt.xlabel(\"o quão similar é\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Criando um gráfico de pizza\n",
    "plt.figure(figsize=(6, 6))\n",
    "obtendo_respostas[\"is_similar\"].value_counts().plot(kind=\"pie\", autopct=\"%1.1f%%\", colors=cores, startangle=90, wedgeprops={\"edgecolor\": \"black\"})\n",
    "plt.title(f'''Proporção de similaridade {QA_avaliado}''')\n",
    "plt.ylabel(\"\")  # Removendo label desnecessário\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Dados das distribuições de similaridade\n",
    "datasets = {\n",
    "    \"qa_pairs_portitulo_15\": [47.18, 0.06, 6.73, 15.52, 0.88, 2.74, 0.90, 11.26, 11.54, 2.44, 0.76],\n",
    "    \"qa_pairs_portitulo_25\": [42.39, 0.00, 6.93, 15.67, 0.80, 3.04, 0.96, 12.90, 13.68, 2.84, 0.80],\n",
    "    \"qa_pairs_portitulo_50\": [34.17, 0.04, 6.43, 16.33, 1.04, 4.01, 0.84, 15.73, 16.37, 3.57, 1.46],\n",
    "    \"qa_pairs_portitulo_100\": [16.95, 0.00, 5.55, 18.89, 1.24, 5.89, 0.78, 20.83, 22.38, 5.25, 2.24],\n",
    "    \"qa_pairs_gerais_15\": [29.47, 0.06, 6.81, 18.13, 0.76, 4.35, 0.76, 16.43, 17.47, 3.99, 1.76],\n",
    "    \"qa_pairs_gerais_25\": [25.32, 0.02, 6.73, 17.97, 1.06, 5.09, 0.72, 17.33, 18.81, 5.03, 1.92],\n",
    "}\n",
    "\n",
    "# Configuração dos gráficos\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(datasets[\"qa_pairs_portitulo_15\"]))  # Posições no eixo X\n",
    "width = 0.15  # Largura das barras\n",
    "\n",
    "# Cores para os datasets\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
    "\n",
    "# Criando barras para cada dataset\n",
    "for i, (label, values) in enumerate(datasets.items()):\n",
    "    ax.bar(x + i * width, values, width, label=label, color=colors[i])\n",
    "\n",
    "# Ajustes no gráfico\n",
    "ax.set_xlabel(\"Níveis de Similaridade\")\n",
    "ax.set_ylabel(\"Percentual (%)\")\n",
    "ax.set_title(\"Comparação das Distribuições de Similaridade\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(range(11))\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Exibir gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_langchain(base: str, qa_passado_df, output_filename: str):\n",
    "\n",
    "    data_df = pd.read_csv(f'''data/{base}.csv''')\n",
    "\n",
    "    chat = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    loader = DataFrameLoader(data_df, page_content_column=\"context\")\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    documents = loader.load()\n",
    "\n",
    "    print('------------------- obtendo documentos para pipeline')\n",
    "    qdrant = Qdrant.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        location=\":memory:\",\n",
    "        collection_name=\"rag\"\n",
    "    )\n",
    "\n",
    "    print('------------------- finalizando documentos para pipeline')\n",
    "\n",
    "    print('------------------- iniciando testes de perguntas e respostas')\n",
    "\n",
    "    results = []\n",
    "    i = 0\n",
    "    total = len(qa_passado_df)\n",
    "    \n",
    "    for index, row in qa_passado_df.iterrows():\n",
    "        query = row[\"question\"]\n",
    "        expected_answer = row[\"answers\"]\n",
    "        \n",
    "        results_retriver = qdrant.similarity_search(query, k=3)\n",
    "        source_knowledge = \"\\n\".join([x.page_content for x in results_retriver])\n",
    "        augment_prompt = f\"\"\"Use the context below to answer the question.\n",
    "\n",
    "        Context:\n",
    "        {source_knowledge}\n",
    "        -------------------------\n",
    "        Succinct answers are necessary, always focusing on answering the question. \n",
    "        To get straight to the point, avoid unnecessary information.\n",
    "        Avoid repeat the question in the answer and focus in the objective answer.\n",
    "        -------------------------\n",
    "        Question: {query}\"\"\"\n",
    "\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a RAG that uses contexts to answer questions.\"),\n",
    "            HumanMessage(content=augment_prompt)\n",
    "        ]\n",
    "\n",
    "        res = chat.invoke(messages)\n",
    "\n",
    "        results.append({\n",
    "            \"title\": row[\"title\"],\n",
    "            \"question\": query,\n",
    "            \"expected_answer\": expected_answer,\n",
    "            \"generated_answer\": res.content,\n",
    "        })\n",
    "        i += 1\n",
    "\n",
    "        print(f\"################### Processando ({i}/{total})...\")\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f'''data/qa_langchain/{output_filename}.csv''', index=False)\n",
    "\n",
    "    print(f\"\\n-------------------Finalizado! Resultados salvos em {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset utilizado na outra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df_usado = pd.read_csv(f'''data/qa/{Contexto.QA_PAIRS.value}_usado.csv''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aplicando em contextos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- obtendo documentos para pipeline\n",
      "------------------- finalizando documentos para pipeline\n",
      "------------------- iniciando testes de perguntas e respostas\n",
      "################### Processando (1/93)...\n",
      "################### Processando (2/93)...\n",
      "################### Processando (3/93)...\n",
      "################### Processando (4/93)...\n",
      "################### Processando (5/93)...\n",
      "################### Processando (6/93)...\n",
      "################### Processando (7/93)...\n",
      "################### Processando (8/93)...\n",
      "################### Processando (9/93)...\n",
      "################### Processando (10/93)...\n",
      "################### Processando (11/93)...\n",
      "################### Processando (12/93)...\n",
      "################### Processando (13/93)...\n",
      "################### Processando (14/93)...\n",
      "################### Processando (15/93)...\n",
      "################### Processando (16/93)...\n",
      "################### Processando (17/93)...\n",
      "################### Processando (18/93)...\n",
      "################### Processando (19/93)...\n",
      "################### Processando (20/93)...\n",
      "################### Processando (21/93)...\n",
      "################### Processando (22/93)...\n",
      "################### Processando (23/93)...\n",
      "################### Processando (24/93)...\n",
      "################### Processando (25/93)...\n",
      "################### Processando (26/93)...\n",
      "################### Processando (27/93)...\n",
      "################### Processando (28/93)...\n",
      "################### Processando (29/93)...\n",
      "################### Processando (30/93)...\n",
      "################### Processando (31/93)...\n",
      "################### Processando (32/93)...\n",
      "################### Processando (33/93)...\n",
      "################### Processando (34/93)...\n",
      "################### Processando (35/93)...\n",
      "################### Processando (36/93)...\n",
      "################### Processando (37/93)...\n",
      "################### Processando (38/93)...\n",
      "################### Processando (39/93)...\n",
      "################### Processando (40/93)...\n",
      "################### Processando (41/93)...\n",
      "################### Processando (42/93)...\n",
      "################### Processando (43/93)...\n",
      "################### Processando (44/93)...\n",
      "################### Processando (45/93)...\n",
      "################### Processando (46/93)...\n",
      "################### Processando (47/93)...\n",
      "################### Processando (48/93)...\n",
      "################### Processando (49/93)...\n",
      "################### Processando (50/93)...\n",
      "################### Processando (51/93)...\n",
      "################### Processando (52/93)...\n",
      "################### Processando (53/93)...\n",
      "################### Processando (54/93)...\n",
      "################### Processando (55/93)...\n",
      "################### Processando (56/93)...\n",
      "################### Processando (57/93)...\n",
      "################### Processando (58/93)...\n",
      "################### Processando (59/93)...\n",
      "################### Processando (60/93)...\n",
      "################### Processando (61/93)...\n",
      "################### Processando (62/93)...\n",
      "################### Processando (63/93)...\n",
      "################### Processando (64/93)...\n",
      "################### Processando (65/93)...\n",
      "################### Processando (66/93)...\n",
      "################### Processando (67/93)...\n",
      "################### Processando (68/93)...\n",
      "################### Processando (69/93)...\n",
      "################### Processando (70/93)...\n",
      "################### Processando (71/93)...\n",
      "################### Processando (72/93)...\n",
      "################### Processando (73/93)...\n",
      "################### Processando (74/93)...\n",
      "################### Processando (75/93)...\n",
      "################### Processando (76/93)...\n",
      "################### Processando (77/93)...\n",
      "################### Processando (78/93)...\n",
      "################### Processando (79/93)...\n",
      "################### Processando (80/93)...\n",
      "################### Processando (81/93)...\n",
      "################### Processando (82/93)...\n",
      "################### Processando (83/93)...\n",
      "################### Processando (84/93)...\n",
      "################### Processando (85/93)...\n",
      "################### Processando (86/93)...\n",
      "################### Processando (87/93)...\n",
      "################### Processando (88/93)...\n",
      "################### Processando (89/93)...\n",
      "################### Processando (90/93)...\n",
      "################### Processando (91/93)...\n",
      "################### Processando (92/93)...\n",
      "################### Processando (93/93)...\n",
      "\n",
      "-------------------Finalizado! Resultados salvos em qa_teste_portitulo\n"
     ]
    }
   ],
   "source": [
    "pipeline_langchain(Contexto.GERAIS_100.value, qa_df_usado, Contexto.QA_PAIRS_GERAIS_100.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_langchain(Contexto.GERAIS_50.value, qa_df_usado, Contexto.QA_PAIRS_GERAIS_50.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_langchain(Contexto.GERAIS_25.value, qa_df_usado, Contexto.QA_PAIRS_GERAIS_25.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_langchain(Contexto.GERAIS_15.value, qa_df_usado, Contexto.QA_PAIRS_GERAIS_15.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_langchain(Contexto.PORTITULO_15.value, qa_df_usado, Contexto.QA_PAIRS_PORTITULO_15.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_langchain(Contexto.PORTITULO_25.value, qa_df_usado, Contexto.QA_PAIRS_PORTITULO_25.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_langchain(Contexto.PORTITULO_50.value, qa_df_usado, Contexto.QA_PAIRS_PORTITULO_50.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_langchain(Contexto.PORTITULO_100.value, qa_df_usado, Contexto.QA_PAIRS_PORTITULO_100.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- avaliacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_GERAIS_100.value, 'qa_langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/gxpxpsfx2y5g_0qfn36b5jcw0000gn/T/ipykernel_77397/3126435904.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[index, 'is_similar'] = is_similar_using_llm(row['expected_answer'], row['generated_answer'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Progresso: 1/93\n",
      "*********** Progresso: 2/93\n",
      "*********** Progresso: 3/93\n",
      "*********** Progresso: 4/93\n",
      "*********** Progresso: 5/93\n",
      "*********** Progresso: 6/93\n",
      "*********** Progresso: 7/93\n",
      "*********** Progresso: 8/93\n",
      "*********** Progresso: 9/93\n",
      "*********** Progresso: 10/93\n",
      "*********** Progresso: 11/93\n",
      "*********** Progresso: 12/93\n",
      "*********** Progresso: 13/93\n",
      "*********** Progresso: 14/93\n",
      "*********** Progresso: 15/93\n",
      "*********** Progresso: 16/93\n",
      "*********** Progresso: 17/93\n",
      "*********** Progresso: 18/93\n",
      "*********** Progresso: 19/93\n",
      "*********** Progresso: 20/93\n",
      "*********** Progresso: 21/93\n",
      "*********** Progresso: 22/93\n",
      "*********** Progresso: 23/93\n",
      "*********** Progresso: 24/93\n",
      "*********** Progresso: 25/93\n",
      "*********** Progresso: 26/93\n",
      "*********** Progresso: 27/93\n",
      "*********** Progresso: 28/93\n",
      "*********** Progresso: 29/93\n",
      "*********** Progresso: 30/93\n",
      "*********** Progresso: 31/93\n",
      "*********** Progresso: 32/93\n",
      "*********** Progresso: 33/93\n",
      "*********** Progresso: 34/93\n",
      "*********** Progresso: 35/93\n",
      "*********** Progresso: 36/93\n",
      "*********** Progresso: 37/93\n",
      "*********** Progresso: 38/93\n",
      "*********** Progresso: 39/93\n",
      "*********** Progresso: 40/93\n",
      "*********** Progresso: 41/93\n",
      "*********** Progresso: 42/93\n",
      "*********** Progresso: 43/93\n",
      "*********** Progresso: 44/93\n",
      "*********** Progresso: 45/93\n",
      "*********** Progresso: 46/93\n",
      "*********** Progresso: 47/93\n",
      "*********** Progresso: 48/93\n",
      "*********** Progresso: 49/93\n",
      "*********** Progresso: 50/93\n",
      "*********** Progresso: 51/93\n",
      "*********** Progresso: 52/93\n",
      "*********** Progresso: 53/93\n",
      "*********** Progresso: 54/93\n",
      "*********** Progresso: 55/93\n",
      "*********** Progresso: 56/93\n",
      "*********** Progresso: 57/93\n",
      "*********** Progresso: 58/93\n",
      "*********** Progresso: 59/93\n",
      "*********** Progresso: 60/93\n",
      "*********** Progresso: 61/93\n",
      "*********** Progresso: 62/93\n",
      "*********** Progresso: 63/93\n",
      "*********** Progresso: 64/93\n",
      "*********** Progresso: 65/93\n",
      "*********** Progresso: 66/93\n",
      "*********** Progresso: 67/93\n",
      "*********** Progresso: 68/93\n",
      "*********** Progresso: 69/93\n",
      "*********** Progresso: 70/93\n",
      "*********** Progresso: 71/93\n",
      "*********** Progresso: 72/93\n",
      "*********** Progresso: 73/93\n",
      "*********** Progresso: 74/93\n",
      "*********** Progresso: 75/93\n",
      "*********** Progresso: 76/93\n",
      "*********** Progresso: 77/93\n",
      "*********** Progresso: 78/93\n",
      "*********** Progresso: 79/93\n",
      "*********** Progresso: 80/93\n",
      "*********** Progresso: 81/93\n",
      "*********** Progresso: 82/93\n",
      "*********** Progresso: 83/93\n",
      "*********** Progresso: 84/93\n",
      "*********** Progresso: 85/93\n",
      "*********** Progresso: 86/93\n",
      "*********** Progresso: 87/93\n",
      "*********** Progresso: 88/93\n",
      "*********** Progresso: 89/93\n",
      "*********** Progresso: 90/93\n",
      "*********** Progresso: 91/93\n",
      "*********** Progresso: 92/93\n",
      "*********** Progresso: 93/93\n"
     ]
    }
   ],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_GERAIS_50.value, 'qa_langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_GERAIS_25.value, 'qa_langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_GERAIS_15.value, 'qa_langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_PORTITULO_100.value, 'qa_langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_PORTITULO_50.value, 'qa_langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_PORTITULO_25.value, 'qa_langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_respostas_usando_llm_contagem(Contexto.QA_PAIRS_PORTITULO_15.value, 'qa_langchain')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
